{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after process data structure for each modality\n",
    "# acoustic = [[[feature at time 1], [feature at time 2], [...]], [...]]\n",
    "# linguistic = [[[token_1, token_2, ... at time 1], [token_1, token_2, ... at time 2], [...]], [...]]\n",
    "# visual = [[[feature at time 1], [feature at time 2], [...]], [...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities_data_dir = \"../../SENDv1-data/features/Train/\"\n",
    "target_data_dir = \"../../SENDv1-data/ratings/Train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = {\n",
    "    'acoustic': lambda df : df.loc[:,' F0semitoneFrom27.5Hz_sma3nz_amean':' equivalentSoundLevel_dBp'],\n",
    "    'acoustic_timer': lambda df : df.loc[:,' frameTime'],\n",
    "    'linguistic': lambda df : df.loc[:,'word'],\n",
    "    'linguistic_timer': lambda df : df.loc[:,'time-offset'],\n",
    "    'target': lambda df : df.loc[:,' rating'],\n",
    "    'target_timer': lambda df : df.loc[:,'time'],\n",
    "}\n",
    "\n",
    "class InputFeature:\n",
    "    \n",
    "    def __init__(\n",
    "        self, video_id=\"\",\n",
    "        acoustic_feature=[],\n",
    "        linguistic_feature=[],\n",
    "        visual_feature=[],\n",
    "        labels=[],\n",
    "    ):\n",
    "        self.video_id = video_id\n",
    "        self.acoustic_feature = acoustic_feature\n",
    "        self.linguistic_feature = linguistic_feature\n",
    "        self.visual_feature = visual_feature\n",
    "        self.labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_SEND_files(\n",
    "    data_dir, # Multitmodal X\n",
    "    target_dir, # Y\n",
    "    time_window_in_sec=5.0,\n",
    "    modality_dir_map = {\"acoustic\": \"acoustic-egemaps\",  \n",
    "                        \"linguistic\": \"linguistic-word-level\", # we don't load features\n",
    "                        \"visual\": \"image-raw\", # image is nested,\n",
    "                        \"target\": \"target\",\n",
    "                       },\n",
    "    linguistic_tokenizer=None,\n",
    "):\n",
    "    SEND_videos = []\n",
    "    \n",
    "    # basically, let us gett all the video ids?\n",
    "    a_ids = [f.split(\"_\")[0]+\"_\"+f.split(\"_\")[1] \n",
    "             for f in listdir(os.path.join(data_dir, modality_dir_map[\"acoustic\"])) \n",
    "             if isfile(os.path.join(data_dir, modality_dir_map[\"acoustic\"], f))]\n",
    "    l_ids = [f.split(\"_\")[0]+\"_\"+f.split(\"_\")[1] \n",
    "             for f in listdir(os.path.join(data_dir, modality_dir_map[\"linguistic\"])) \n",
    "             if isfile(os.path.join(data_dir, modality_dir_map[\"linguistic\"], f))]\n",
    "    v_ids = [f.split(\"_\")[0]+\"_\"+f.split(\"_\")[1] \n",
    "             for f in listdir(os.path.join(data_dir, modality_dir_map[\"visual\"])) \n",
    "             if f != \".DS_Store\"]\n",
    "    assert len(a_ids) == len(l_ids) and len(l_ids) == len(v_ids)\n",
    "    assert len(set(a_ids).intersection(set(l_ids))) == len(l_ids)\n",
    "    assert len(set(a_ids).intersection(set(v_ids))) == len(v_ids)\n",
    "    \n",
    "    # We need the first pass for linguistic modality process?\n",
    "    max_window_l_length = -1\n",
    "    for video_id in a_ids: # pick any one!\n",
    "        # linguistic features process\n",
    "        l_file = os.path.join(data_dir, modality_dir_map[\"linguistic\"], f\"{video_id}_aligned.tsv\")\n",
    "        l_df = pd.read_csv(l_file, sep='\\t')\n",
    "        l_words = np.array(preprocess[\"linguistic\"](l_df))\n",
    "        l_words = [w.strip().lower() for w in l_words]\n",
    "        l_timestamps = np.array(preprocess[\"linguistic_timer\"](l_df))\n",
    "        # sample based on interval\n",
    "        current_time = 0.0\n",
    "        keep_first = True\n",
    "        sampled_l_words = [] # different from other modality, it is essentially a list of list!\n",
    "        tmp_words = []\n",
    "        for i in range(0, l_timestamps.shape[0]):\n",
    "            if keep_first:\n",
    "                sampled_l_words += [[]]\n",
    "                keep_first = False\n",
    "            if l_timestamps[i] >= current_time+time_window_in_sec:\n",
    "                sampled_l_words.append(tmp_words)\n",
    "                tmp_words = [l_words[i]] # reinit the buffer\n",
    "                current_time += time_window_in_sec\n",
    "                continue\n",
    "            tmp_words += [l_words[i]]\n",
    "        # overflow\n",
    "        if len(tmp_words) > 0:\n",
    "            sampled_l_words.append(tmp_words)\n",
    "        for window_words in sampled_l_words:\n",
    "            token_ids = linguistic_tokenizer.convert_tokens_to_ids(window_words)\n",
    "            if len(token_ids) > max_window_l_length:\n",
    "                max_window_l_length = len(token_ids)\n",
    "    max_window_l_length += 2 # the start and the end token\n",
    "    \n",
    "    video_count = 0\n",
    "    for video_id in a_ids: # pick any one!\n",
    "        if video_count > 1 and video_count%100 == 0:\n",
    "            logger.info(f\"Processed #{len(SEND_videos)} videos.\")\n",
    "            logger.info(SEND_videos[-1])\n",
    "        \n",
    "        # we need to fix this to get features aligned.\n",
    "        \n",
    "        # Step 1: Load rating data, and we can get window partitioned according to our interval.\n",
    "        target_id = video_id.split(\"_\")[0][2:] + \"_\" + video_id.split(\"_\")[1][3:]\n",
    "        target_file = os.path.join(target_data_dir, modality_dir_map[\"target\"], f\"target_{target_id}_normal.csv\")\n",
    "        target_df = pd.read_csv(target_file)\n",
    "        target_ratings = np.array(preprocess[\"target\"](target_df))\n",
    "        target_timestamps = np.array(preprocess[\"target_timer\"](target_df))\n",
    "        assert target_ratings.shape[0] == target_timestamps.shape[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # acoustic features process\n",
    "        a_file = os.path.join(data_dir, modality_dir_map[\"acoustic\"], f\"{video_id}_acousticFeatures.csv\")\n",
    "        a_df = pd.read_csv(a_file)\n",
    "        a_features = np.array(preprocess[\"acoustic\"](a_df))\n",
    "        a_timestamps = np.array(preprocess[\"acoustic_timer\"](a_df))\n",
    "        assert a_features.shape[0] == a_timestamps.shape[0]\n",
    "        # sample based on interval\n",
    "        current_time = 0.0\n",
    "        keep_first = True\n",
    "        sampled_a_features = []\n",
    "        sampled_a_timestamps  = []\n",
    "        tmp_a_features = []\n",
    "        for i in range(0, a_timestamps.shape[0]):\n",
    "            if keep_first:\n",
    "                sampled_a_features += [a_features[i]]\n",
    "                sampled_a_timestamps += [a_timestamps[i]]\n",
    "                keep_first = False\n",
    "            if a_timestamps[i] >= current_time+time_window_in_sec:\n",
    "                tmp_a_features = np.mean(np.array(tmp_a_features), axis=0)\n",
    "                sampled_a_features += [tmp_a_features]\n",
    "                this_timestamp = current_time+time_window_in_sec\n",
    "                sampled_a_timestamps += [this_timestamp]\n",
    "                current_time += time_window_in_sec\n",
    "                tmp_a_features = [a_features[i]]\n",
    "                continue\n",
    "            tmp_a_features += [a_features[i]]\n",
    "        sampled_a_features = np.array(sampled_a_features)\n",
    "        sampled_a_timestamps = np.array(sampled_a_timestamps)\n",
    "        assert sampled_a_features.shape[0] == sampled_a_timestamps.shape[0]\n",
    "        \n",
    "        \n",
    "        # linguistic features process\n",
    "        l_file = os.path.join(data_dir, modality_dir_map[\"linguistic\"], f\"{video_id}_aligned.tsv\")\n",
    "        l_df = pd.read_csv(l_file, sep='\\t')\n",
    "        l_words = np.array(preprocess[\"linguistic\"](l_df))\n",
    "        l_words = [w.strip().lower() for w in l_words]\n",
    "        l_timestamps = np.array(preprocess[\"linguistic_timer\"](l_df))\n",
    "        assert len(l_words) == l_timestamps.shape[0]\n",
    "        # sample based on interval\n",
    "        current_time = 0.0\n",
    "        keep_first = True\n",
    "        sampled_l_words = [] # different from other modality, it is essentially a list of list!\n",
    "        sampled_l_timestamps = []\n",
    "        tmp_words = []\n",
    "        for i in range(0, l_timestamps.shape[0]):\n",
    "            if keep_first:\n",
    "                sampled_l_words += [[]]\n",
    "                sampled_l_timestamps += [0.0]\n",
    "                keep_first = False\n",
    "            if l_timestamps[i] >= current_time+time_window_in_sec:\n",
    "                sampled_l_words.append(tmp_words)\n",
    "                this_timestampe = current_time+time_window_in_sec\n",
    "                sampled_l_timestamps += [this_timestampe]\n",
    "                tmp_words = [l_words[i]] # reinit the buffer\n",
    "                current_time += time_window_in_sec\n",
    "                continue\n",
    "            tmp_words += [l_words[i]]\n",
    "        # overflow\n",
    "        if len(tmp_words) > 0:\n",
    "            sampled_l_words.append(tmp_words)\n",
    "            this_timestampe = current_time+time_window_in_sec\n",
    "            sampled_l_timestamps += [this_timestampe]\n",
    "        sampled_l_timestamps = np.array(sampled_l_timestamps)\n",
    "        sampled_l_token_ids = []\n",
    "        sampled_l_window_length = []\n",
    "        for window_words in sampled_l_words:\n",
    "            complete_window_word = [\"[CLS]\"] + window_words + [\"[SEP]\"]\n",
    "            token_ids = linguistic_tokenizer.convert_tokens_to_ids(complete_window_word)\n",
    "            sampled_l_window_length += [len(token_ids)]\n",
    "            for _ in range(0, max_window_l_length-len(token_ids)):\n",
    "                token_ids.append(linguistic_tokenizer.pad_token_id)\n",
    "            sampled_l_token_ids += [token_ids]\n",
    "        assert len(sampled_l_words) == sampled_l_timestamps.shape[0]\n",
    "        assert len(sampled_l_token_ids) == sampled_l_timestamps.shape[0]\n",
    "        \n",
    "        \n",
    "        # visual features process\n",
    "        # for visual, we actually need to active control what image we load, we\n",
    "        # cannot just load all images, it will below memory.\n",
    "        fps=30 # We may need to dynamically figure out this number?\n",
    "        frame_names = []\n",
    "        for f in listdir(os.path.join(data_dir, modality_dir_map[\"visual\"], video_id)):\n",
    "            if \".jpg\" in f:\n",
    "                frame_names += [(int(f.split(\"_\")[0][5:])*(1.0/fps), f)]\n",
    "        frame_names.sort(key=lambda x:x[0])\n",
    "        sampled_frames = []\n",
    "        current_time = 0.0\n",
    "        keep_first = True\n",
    "        for f in frame_names:\n",
    "            if keep_first:\n",
    "                sampled_frames += [f]\n",
    "                keep_first = False\n",
    "            if f[0] >= current_time+time_window_in_sec:\n",
    "                sampled_frames += [f]\n",
    "                current_time += time_window_in_sec\n",
    "        v_images = []\n",
    "        v_timestamps = []\n",
    "        for f in sampled_frames:\n",
    "            f_path = os.path.join(data_dir, modality_dir_map[\"visual\"], video_id, f[1])\n",
    "            f_image = Image.open(f_path)\n",
    "            f_data = asarray(f_image)\n",
    "            v_images += [f_data] \n",
    "            v_timestamps += [f[0]]\n",
    "        v_images = np.array(v_images)\n",
    "        v_timestamps = np.array(v_timestamps)\n",
    "        \n",
    "        \n",
    "        # ratings (target)\n",
    "        target_id = video_id.split(\"_\")[0][2:] + \"_\" + video_id.split(\"_\")[1][3:]\n",
    "        target_file = os.path.join(target_data_dir, modality_dir_map[\"target\"], f\"target_{target_id}_normal.csv\")\n",
    "        target_df = pd.read_csv(target_file)\n",
    "        target_ratings = np.array(preprocess[\"target\"](target_df))\n",
    "        target_timestamps = np.array(preprocess[\"target_timer\"](target_df))\n",
    "        assert target_ratings.shape[0] == target_timestamps.shape[0]\n",
    "        # sample based on interval\n",
    "        current_time = 0.0\n",
    "        keep_first = True\n",
    "        sampled_target_ratings = []\n",
    "        sampled_target_timestamps  = []\n",
    "        tmp_target_ratings = []\n",
    "        for i in range(0, target_timestamps.shape[0]):\n",
    "            if keep_first:\n",
    "                sampled_target_ratings += [0.5]\n",
    "                sampled_target_timestamps += [0.0]\n",
    "                keep_first = False\n",
    "            if target_timestamps[i] >= current_time+time_window_in_sec:\n",
    "                this_rating = sum(tmp_target_ratings)/len(tmp_target_ratings)\n",
    "                sampled_target_ratings += [this_rating]\n",
    "                this_timestampe = current_time+time_window_in_sec\n",
    "                sampled_target_timestamps += [this_timestampe]\n",
    "                tmp_target_ratings = [target_ratings[i]]\n",
    "                current_time += time_window_in_sec\n",
    "                continue\n",
    "            tmp_target_ratings += [target_ratings[i]]\n",
    "        # overflow\n",
    "        if len(tmp_target_ratings) > 0:\n",
    "            this_rating = sum(tmp_target_ratings)/len(tmp_target_ratings)\n",
    "            sampled_target_ratings.append(this_rating)\n",
    "            this_timestampe = current_time+time_window_in_sec\n",
    "            sampled_target_timestamps += [this_timestampe]\n",
    "        sampled_target_ratings = np.array(sampled_target_ratings)\n",
    "        sampled_target_timestamps = np.array(sampled_target_timestamps)\n",
    "        assert sampled_target_ratings.shape[0] == sampled_target_timestamps.shape[0]\n",
    "        \n",
    "        video_struct = {\n",
    "            \"video_id\": video_id,\n",
    "            \"a_feature\": sampled_a_features,\n",
    "            \"a_timer\": sampled_a_timestamps,\n",
    "            \"l_feature\": sampled_l_token_ids,\n",
    "            \"l_inwindow_length\": sampled_l_window_length,\n",
    "            \"l_timer\": sampled_l_timestamps,\n",
    "            \"v_feature\": v_images,\n",
    "            \"v_timer\": v_timestamps,\n",
    "            \"r\": sampled_target_ratings,\n",
    "            \"r_timer\": sampled_target_timestamps,\n",
    "        }\n",
    "        video_count += 1\n",
    "        SEND_videos += [video_struct]\n",
    "        print(video_struct)\n",
    "        \n",
    "        break\n",
    "        \n",
    "    return SEND_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    use_fast=False,\n",
    "    cache_dir=\"../.huggingface_cache/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_id': 'ID162_vid4', 'a_feature': array([[ 1.96395800e+01,  9.25502700e-02,  1.79369000e+01, ...,\n",
      "         5.00000000e-02,  3.00000000e-02, -3.19951500e+01],\n",
      "       [ 2.33612200e+01,  1.36073739e-01,  2.04801220e+01, ...,\n",
      "         6.71666660e-02,  1.81246690e-02, -3.00094960e+01],\n",
      "       [ 2.00474110e+01,  1.68061494e-01,  1.73047470e+01, ...,\n",
      "         6.30000000e-02,  3.00000000e-03, -3.51375060e+01],\n",
      "       ...,\n",
      "       [ 1.94123810e+01,  1.45793940e-01,  1.71546900e+01, ...,\n",
      "         6.96666660e-02,  1.30912060e-02, -3.61036850e+01],\n",
      "       [ 1.90082020e+01,  1.58153399e-01,  1.66785640e+01, ...,\n",
      "         8.81666670e-02,  1.61996730e-02, -3.75135450e+01],\n",
      "       [ 1.90940720e+01,  1.35960025e-01,  1.67032110e+01, ...,\n",
      "         4.73333330e-02,  1.45042950e-02, -3.53600390e+01]]), 'a_timer': array([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,\n",
      "        55.,  60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105.,\n",
      "       110., 115., 120., 125., 130., 135., 140., 145., 150.]), 'l_feature': [[101, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2043, 1045, 2001, 7763, 100, 2034, 2051, 1045, 2001, 1999, 2293, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2005, 100, 1045, 2228, 1045, 2196, 11333, 100, 2196, 2001, 1999, 2293, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2077, 100, 2008, 2001, 1996, 2034, 2051, 1045, 2001, 1999, 2293, 2007, 2619, 2008, 2001, 2066, 100, 1045, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3984, 2116, 2111, 2113, 2008, 100, 1045, 3246, 2017, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2074, 2514, 2066, 100, 2061, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1997, 2673, 2003, 2061, 100, 2066, 2074, 2156, 2008, 2711, 2066, 2045, 2017, 100, 2115, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2540, 2003, 2066, 6012, 1037, 3634, 2335, 1037, 2117, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 100, 2017, 2514, 2061, 100, 100, 1045, 100, 100, 100, 2066, 100, 2017, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1996, 3110, 1997, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 2055, 1037, 100, 2066, 100, 2200, 100, 2138, 1045, 2001, 2061, 100, 1045, 2001, 2014, 2767, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 1045, 2001, 2066, 100, 1045, 2196, 2371, 1999, 2293, 2007, 2619, 2030, 2018, 1037, 3276, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2077, 100, 2061, 2009, 2001, 2785, 1997, 100, 100, 2066, 100, 3100, 1045, 2064, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2991, 1999, 3062, 1045, 1045, 2064, 2991, 1999, 2293, 100, 1998, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2031, 2619, 1999, 2026, 2166, 2008, 2001, 100, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 4606, 1996, 2711, 2001, 2200, 3835, 1998, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 100, 2061, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3893, 100, 2130, 2295, 2009, 2001, 8552, 3276, 100, 2059, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2001, 2428, 100, 1045, 3030, 1042, 1045, 2001, 1037, 2200, 2204, 2066, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2152, 2082, 3076, 2001, 2066, 2028, 1997, 1996, 2190, 1999, 2026, 2465, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 1998, 3402, 1045, 3030, 11922, 2055, 2066, 2151, 2118, 2030, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 1045, 2074, 2066, 4711, 3294, 23657, 2013, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 2476, 1998, 100, 100, 2066, 2005, 2048, 2086, 2061, 2028, 2095, 1045, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2106, 2066, 1037, 100, 6578, 2096, 1045, 6158, 1037, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2978, 1998, 1045, 2001, 4208, 2006, 2026, 3276, 1998, 1996, 2117, 2095, 1045, 2253, 2000, 2047, 2259, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 100, 1045, 3984, 1045, 2785, 1997, 3478, 2138, 2008, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 2025, 1037, 3634, 3867, 2138, 1997, 2008, 3276, 2138, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2009, 2001, 2205, 2205, 2116, 100, 2009, 2001, 2066, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2635, 2066, 13568, 3867, 1997, 2026, 100, 2066, 2008, 2001, 2205, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 2205, 2172, 6699, 1998, 3398, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 1045, 100, 100, 2021, 100, 100, 2061, 2008, 2001, 2026, 2034, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 1045, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'l_inwindow_length': [2, 13, 14, 20, 12, 9, 17, 11, 17, 7, 19, 18, 16, 13, 12, 11, 6, 12, 14, 15, 13, 11, 15, 11, 20, 12, 12, 11, 13, 8, 14, 6], 'l_timer': array([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,\n",
      "        55.,  60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105.,\n",
      "       110., 115., 120., 125., 130., 135., 140., 145., 150., 155.]), 'v_feature': array([[[[ 42,  38,  37],\n",
      "         [ 42,  38,  37],\n",
      "         [ 43,  39,  38],\n",
      "         ...,\n",
      "         [ 83,  49,  50],\n",
      "         [ 79,  47,  48],\n",
      "         [ 78,  46,  49]],\n",
      "\n",
      "        [[ 41,  37,  36],\n",
      "         [ 42,  38,  37],\n",
      "         [ 42,  38,  37],\n",
      "         ...,\n",
      "         [ 83,  49,  50],\n",
      "         [ 79,  47,  48],\n",
      "         [ 78,  46,  49]],\n",
      "\n",
      "        [[ 41,  37,  36],\n",
      "         [ 42,  38,  37],\n",
      "         [ 42,  38,  37],\n",
      "         ...,\n",
      "         [ 82,  48,  49],\n",
      "         [ 78,  46,  47],\n",
      "         [ 76,  46,  48]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 28,  25,  36],\n",
      "         [ 31,  29,  40],\n",
      "         [ 39,  38,  46],\n",
      "         ...,\n",
      "         [ 32,  29,  36],\n",
      "         [ 30,  27,  34],\n",
      "         [ 29,  26,  33]],\n",
      "\n",
      "        [[ 29,  27,  40],\n",
      "         [ 33,  31,  44],\n",
      "         [ 42,  40,  51],\n",
      "         ...,\n",
      "         [ 34,  31,  38],\n",
      "         [ 31,  28,  35],\n",
      "         [ 29,  26,  33]],\n",
      "\n",
      "        [[ 30,  28,  41],\n",
      "         [ 35,  33,  46],\n",
      "         [ 43,  41,  52],\n",
      "         ...,\n",
      "         [ 35,  32,  39],\n",
      "         [ 32,  29,  36],\n",
      "         [ 30,  27,  34]]],\n",
      "\n",
      "\n",
      "       [[[ 93,  59,  49],\n",
      "         [ 93,  59,  49],\n",
      "         [ 95,  59,  47],\n",
      "         ...,\n",
      "         [ 38,  38,  38],\n",
      "         [ 39,  37,  38],\n",
      "         [ 39,  37,  38]],\n",
      "\n",
      "        [[ 92,  58,  48],\n",
      "         [ 93,  59,  49],\n",
      "         [ 94,  58,  46],\n",
      "         ...,\n",
      "         [ 37,  37,  37],\n",
      "         [ 39,  37,  38],\n",
      "         [ 39,  37,  38]],\n",
      "\n",
      "        [[ 91,  57,  47],\n",
      "         [ 92,  58,  48],\n",
      "         [ 93,  57,  45],\n",
      "         ...,\n",
      "         [ 38,  36,  37],\n",
      "         [ 38,  36,  37],\n",
      "         [ 38,  36,  37]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 35,  29,  31],\n",
      "         [ 34,  28,  30],\n",
      "         [ 33,  27,  29],\n",
      "         ...,\n",
      "         [ 62,  58,  72],\n",
      "         [ 56,  52,  66],\n",
      "         [ 53,  49,  63]],\n",
      "\n",
      "        [[ 34,  28,  30],\n",
      "         [ 34,  28,  30],\n",
      "         [ 33,  27,  27],\n",
      "         ...,\n",
      "         [ 73,  69,  83],\n",
      "         [ 69,  65,  79],\n",
      "         [ 67,  63,  77]],\n",
      "\n",
      "        [[ 36,  27,  30],\n",
      "         [ 34,  28,  30],\n",
      "         [ 33,  27,  27],\n",
      "         ...,\n",
      "         [ 80,  76,  90],\n",
      "         [ 76,  72,  87],\n",
      "         [ 74,  70,  85]]],\n",
      "\n",
      "\n",
      "       [[[118,  98,  97],\n",
      "         [122, 103,  99],\n",
      "         [131, 112, 108],\n",
      "         ...,\n",
      "         [ 59,  49,  47],\n",
      "         [ 57,  47,  45],\n",
      "         [ 56,  46,  44]],\n",
      "\n",
      "        [[118,  98,  97],\n",
      "         [121, 102,  98],\n",
      "         [130, 111, 107],\n",
      "         ...,\n",
      "         [ 57,  47,  45],\n",
      "         [ 56,  46,  44],\n",
      "         [ 55,  45,  43]],\n",
      "\n",
      "        [[117,  98,  94],\n",
      "         [120, 101,  97],\n",
      "         [128, 109, 105],\n",
      "         ...,\n",
      "         [ 56,  46,  44],\n",
      "         [ 55,  45,  43],\n",
      "         [ 55,  44,  42]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 33,  28,  32],\n",
      "         [ 33,  28,  32],\n",
      "         [ 33,  28,  32],\n",
      "         ...,\n",
      "         [ 67,  43,  33],\n",
      "         [ 59,  36,  28],\n",
      "         [ 55,  32,  24]],\n",
      "\n",
      "        [[ 33,  28,  32],\n",
      "         [ 33,  28,  32],\n",
      "         [ 33,  28,  32],\n",
      "         ...,\n",
      "         [ 80,  56,  44],\n",
      "         [ 69,  47,  36],\n",
      "         [ 64,  41,  33]],\n",
      "\n",
      "        [[ 33,  28,  32],\n",
      "         [ 33,  28,  32],\n",
      "         [ 33,  28,  32],\n",
      "         ...,\n",
      "         [ 84,  60,  48],\n",
      "         [ 72,  50,  39],\n",
      "         [ 66,  44,  33]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 58,  48,  47],\n",
      "         [ 62,  52,  50],\n",
      "         [ 76,  65,  63],\n",
      "         ...,\n",
      "         [ 48,  34,  25],\n",
      "         [ 48,  34,  25],\n",
      "         [ 48,  34,  25]],\n",
      "\n",
      "        [[ 57,  47,  46],\n",
      "         [ 62,  52,  50],\n",
      "         [ 77,  66,  64],\n",
      "         ...,\n",
      "         [ 47,  33,  24],\n",
      "         [ 47,  33,  24],\n",
      "         [ 47,  33,  24]],\n",
      "\n",
      "        [[ 57,  47,  46],\n",
      "         [ 63,  53,  51],\n",
      "         [ 78,  67,  65],\n",
      "         ...,\n",
      "         [ 46,  32,  23],\n",
      "         [ 46,  32,  23],\n",
      "         [ 46,  32,  23]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 32,  30,  31],\n",
      "         [ 31,  29,  30],\n",
      "         [ 31,  29,  30],\n",
      "         ...,\n",
      "         [ 60,  49,  57],\n",
      "         [ 62,  51,  59],\n",
      "         [ 63,  52,  60]],\n",
      "\n",
      "        [[ 31,  29,  30],\n",
      "         [ 31,  29,  30],\n",
      "         [ 31,  29,  30],\n",
      "         ...,\n",
      "         [ 62,  51,  59],\n",
      "         [ 66,  55,  63],\n",
      "         [ 67,  56,  64]],\n",
      "\n",
      "        [[ 31,  29,  30],\n",
      "         [ 31,  29,  30],\n",
      "         [ 31,  29,  30],\n",
      "         ...,\n",
      "         [ 64,  53,  61],\n",
      "         [ 68,  57,  65],\n",
      "         [ 70,  59,  67]]],\n",
      "\n",
      "\n",
      "       [[[102,  75,  58],\n",
      "         [103,  76,  59],\n",
      "         [104,  77,  60],\n",
      "         ...,\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38]],\n",
      "\n",
      "        [[ 99,  72,  55],\n",
      "         [100,  73,  56],\n",
      "         [101,  74,  57],\n",
      "         ...,\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38]],\n",
      "\n",
      "        [[ 89,  62,  45],\n",
      "         [ 90,  63,  46],\n",
      "         [ 91,  64,  47],\n",
      "         ...,\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 31,  29,  32],\n",
      "         [ 31,  29,  32],\n",
      "         [ 33,  28,  32],\n",
      "         ...,\n",
      "         [ 80,  77,  94],\n",
      "         [ 74,  71,  88],\n",
      "         [ 70,  67,  84]],\n",
      "\n",
      "        [[ 30,  28,  31],\n",
      "         [ 31,  29,  32],\n",
      "         [ 33,  28,  32],\n",
      "         ...,\n",
      "         [ 88,  85, 102],\n",
      "         [ 84,  81,  98],\n",
      "         [ 81,  78,  95]],\n",
      "\n",
      "        [[ 30,  28,  31],\n",
      "         [ 31,  29,  32],\n",
      "         [ 33,  28,  32],\n",
      "         ...,\n",
      "         [ 93,  90, 107],\n",
      "         [ 90,  87, 104],\n",
      "         [ 88,  85, 102]]],\n",
      "\n",
      "\n",
      "       [[[205, 146, 130],\n",
      "         [203, 144, 128],\n",
      "         [198, 139, 123],\n",
      "         ...,\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38]],\n",
      "\n",
      "        [[204, 145, 129],\n",
      "         [202, 143, 127],\n",
      "         [198, 139, 123],\n",
      "         ...,\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38]],\n",
      "\n",
      "        [[203, 144, 128],\n",
      "         [202, 143, 127],\n",
      "         [200, 141, 125],\n",
      "         ...,\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38],\n",
      "         [ 41,  37,  38]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 35,  28,  35],\n",
      "         [ 34,  29,  35],\n",
      "         [ 32,  30,  35],\n",
      "         ...,\n",
      "         [ 30,  27,  36],\n",
      "         [ 28,  25,  34],\n",
      "         [ 27,  24,  33]],\n",
      "\n",
      "        [[ 35,  28,  35],\n",
      "         [ 35,  28,  35],\n",
      "         [ 32,  30,  35],\n",
      "         ...,\n",
      "         [ 32,  29,  38],\n",
      "         [ 29,  26,  35],\n",
      "         [ 29,  26,  35]],\n",
      "\n",
      "        [[ 37,  27,  35],\n",
      "         [ 35,  28,  35],\n",
      "         [ 32,  30,  35],\n",
      "         ...,\n",
      "         [ 34,  31,  40],\n",
      "         [ 30,  27,  36],\n",
      "         [ 29,  26,  35]]]], dtype=uint8), 'v_timer': array([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,\n",
      "        55.,  60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105.,\n",
      "       110., 115., 120., 125., 130., 135., 140., 145., 150.]), 'r': array([0.5       , 0.607     , 0.607     , 0.607     , 0.607     ,\n",
      "       0.607     , 0.6768    , 0.7535    , 0.807     , 0.807     ,\n",
      "       0.807     , 0.807     , 0.807     , 0.807     , 0.807     ,\n",
      "       0.8424    , 0.888     , 0.888     , 0.888     , 0.8393    ,\n",
      "       0.802     , 0.802     , 0.802     , 0.786     , 0.763     ,\n",
      "       0.7473    , 0.547     , 0.567     , 0.567     , 0.567     ,\n",
      "       0.567     , 0.60885714]), 'r_timer': array([  0.,   5.,  10.,  15.,  20.,  25.,  30.,  35.,  40.,  45.,  50.,\n",
      "        55.,  60.,  65.,  70.,  75.,  80.,  85.,  90.,  95., 100., 105.,\n",
      "       110., 115., 120., 125., 130., 135., 140., 145., 150., 155.])}\n"
     ]
    }
   ],
   "source": [
    "SEND_features = preprocess_SEND_files(\n",
    "    modalities_data_dir,\n",
    "    target_data_dir,\n",
    "    linguistic_tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
